{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Differential Evolution for Feature Selection\n",
        "\n",
        "This notebook implements Differential Evolution (DE) for feature selection on benchmark metaheuristic datasets.\n",
        "\n",
        "## Overview\n",
        "- Continuous representation internally, converted to binary feature subsets\n",
        "- Differential mutation (DE/rand/1/bin strategy)\n",
        "- Binomial crossover\n",
        "- Greedy selection\n",
        "- Comprehensive visualizations of the evolutionary process\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, matthews_corrcoef\n",
        "from sklearn.datasets import (load_breast_cancer, load_wine, load_iris, make_classification,\n",
        "                             load_digits, load_diabetes, fetch_covtype, load_linnerud)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Dataset Loading and Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_benchmark_dataset(dataset_name='breast_cancer'):\n",
        "    \"\"\"\n",
        "    Load benchmark datasets for feature selection\n",
        "    \n",
        "    Args:\n",
        "        dataset_name: Name of the dataset\n",
        "    \n",
        "    Returns:\n",
        "        X: Feature matrix\n",
        "        y: Target vector\n",
        "        feature_names: List of feature names\n",
        "    \"\"\"\n",
        "    if dataset_name == 'breast_cancer':\n",
        "        data = load_breast_cancer()\n",
        "        X, y = data.data, data.target\n",
        "        feature_names = data.feature_names\n",
        "    elif dataset_name == 'wine':\n",
        "        data = load_wine()\n",
        "        X, y = data.data, data.target\n",
        "        feature_names = data.feature_names\n",
        "    elif dataset_name == 'iris':\n",
        "        data = load_iris()\n",
        "        X, y = data.data, data.target\n",
        "        feature_names = data.feature_names\n",
        "    elif dataset_name == 'digits':\n",
        "        data = load_digits()\n",
        "        X, y = data.data, data.target\n",
        "        feature_names = [f'Pixel_{i+1}' for i in range(X.shape[1])]\n",
        "    elif dataset_name == 'diabetes':\n",
        "        data = load_diabetes()\n",
        "        X, y = data.data, data.target\n",
        "        # Convert regression to binary classification (threshold at median)\n",
        "        y = (y > np.median(y)).astype(int)\n",
        "        feature_names = data.feature_names\n",
        "    elif dataset_name == 'synthetic_1':\n",
        "        # Synthetic dataset 1: Small, balanced\n",
        "        X, y = make_classification(\n",
        "            n_samples=500,\n",
        "            n_features=20,\n",
        "            n_informative=8,\n",
        "            n_redundant=5,\n",
        "            n_repeated=0,\n",
        "            n_classes=2,\n",
        "            n_clusters_per_class=1,\n",
        "            random_state=42\n",
        "        )\n",
        "        feature_names = [f'Feature_{i+1}' for i in range(X.shape[1])]\n",
        "    elif dataset_name == 'synthetic_2':\n",
        "        # Synthetic dataset 2: Medium, multi-class\n",
        "        X, y = make_classification(\n",
        "            n_samples=1000,\n",
        "            n_features=30,\n",
        "            n_informative=10,\n",
        "            n_redundant=10,\n",
        "            n_repeated=0,\n",
        "            n_classes=3,\n",
        "            n_clusters_per_class=1,\n",
        "            random_state=43\n",
        "        )\n",
        "        feature_names = [f'Feature_{i+1}' for i in range(X.shape[1])]\n",
        "    elif dataset_name == 'synthetic_3':\n",
        "        # Synthetic dataset 3: Large, high-dimensional\n",
        "        X, y = make_classification(\n",
        "            n_samples=800,\n",
        "            n_features=50,\n",
        "            n_informative=15,\n",
        "            n_redundant=20,\n",
        "            n_repeated=0,\n",
        "            n_classes=2,\n",
        "            n_clusters_per_class=2,\n",
        "            random_state=44\n",
        "        )\n",
        "        feature_names = [f'Feature_{i+1}' for i in range(X.shape[1])]\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown dataset: {dataset_name}\")\n",
        "    \n",
        "    # Standardize features\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    \n",
        "    print(f\"Dataset: {dataset_name}\")\n",
        "    print(f\"  Samples: {X.shape[0]}, Features: {X.shape[1]}, Classes: {len(np.unique(y))}\")\n",
        "    \n",
        "    return X_scaled, y, feature_names\n",
        "\n",
        "# Define all benchmark datasets to test\n",
        "BENCHMARK_DATASETS = [\n",
        "    'breast_cancer',\n",
        "    'wine',\n",
        "    'iris',\n",
        "    'digits',\n",
        "    'diabetes',\n",
        "    'synthetic_1',\n",
        "    'synthetic_2',\n",
        "    'synthetic_3'\n",
        "]\n",
        "\n",
        "print(f\"Available benchmark datasets: {BENCHMARK_DATASETS}\")\n",
        "print(f\"Total datasets: {len(BENCHMARK_DATASETS)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Differential Evolution Implementation\n",
        "\n",
        "### 3.1 Representation and Initialization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def initialize_population(pop_size, n_features, lower_bound=0.0, upper_bound=1.0):\n",
        "    \"\"\"\n",
        "    Initialize population of continuous vectors\n",
        "    \n",
        "    Args:\n",
        "        pop_size: Population size\n",
        "        n_features: Number of features\n",
        "        lower_bound: Lower bound for initialization (default 0.0)\n",
        "        upper_bound: Upper bound for initialization (default 1.0)\n",
        "    \n",
        "    Returns:\n",
        "        population: Array of shape (pop_size, n_features) with continuous values in [lower_bound, upper_bound]\n",
        "    \"\"\"\n",
        "    population = np.random.uniform(lower_bound, upper_bound, size=(pop_size, n_features))\n",
        "    return population\n",
        "\n",
        "def continuous_to_binary(continuous_vector, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Convert continuous vector to binary chromosome\n",
        "    \n",
        "    Args:\n",
        "        continuous_vector: Continuous values in [0, 1]\n",
        "        threshold: Threshold for conversion (default 0.5)\n",
        "    \n",
        "    Returns:\n",
        "        binary_vector: Binary array\n",
        "    \"\"\"\n",
        "    binary = (continuous_vector >= threshold).astype(int)\n",
        "    \n",
        "    # Ensure at least one feature is selected\n",
        "    if np.sum(binary) == 0:\n",
        "        # Select the feature with highest continuous value\n",
        "        binary[np.argmax(continuous_vector)] = 1\n",
        "    \n",
        "    return binary\n",
        "\n",
        "print(\"Population initialization functions defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Fitness Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_fitness(continuous_vector, X, y, classifier='rf', cv_folds=5, metric='accuracy', \n",
        "                     alpha=1.0, beta=0.0, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Evaluate fitness of a continuous vector (converted to binary feature subset)\n",
        "    \n",
        "    Fitness = α * Performance - β * (|X|/n)\n",
        "    \n",
        "    Args:\n",
        "        continuous_vector: Continuous values in [0, 1]\n",
        "        X: Feature matrix\n",
        "        y: Target vector\n",
        "        classifier: Type of classifier ('rf', 'svm', 'knn')\n",
        "        cv_folds: Number of cross-validation folds\n",
        "        metric: Performance metric ('accuracy', 'f1', 'mcc', 'roc_auc')\n",
        "        alpha: Weight for performance term\n",
        "        beta: Weight for size penalty term\n",
        "        threshold: Threshold for converting continuous to binary\n",
        "    \n",
        "    Returns:\n",
        "        fitness: Fitness value\n",
        "        performance: Performance metric value\n",
        "    \"\"\"\n",
        "    # Convert continuous to binary\n",
        "    chromosome = continuous_to_binary(continuous_vector, threshold=threshold)\n",
        "    \n",
        "    # Get selected features\n",
        "    selected_features = np.where(chromosome == 1)[0]\n",
        "    \n",
        "    # If no features selected, return low fitness\n",
        "    if len(selected_features) == 0:\n",
        "        return 0.0, 0.0\n",
        "    \n",
        "    # Select features\n",
        "    X_selected = X[:, selected_features]\n",
        "    \n",
        "    # Initialize classifier\n",
        "    if classifier == 'rf':\n",
        "        clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "    elif classifier == 'svm':\n",
        "        clf = SVC(kernel='rbf', random_state=42, probability=True)\n",
        "    elif classifier == 'knn':\n",
        "        clf = KNeighborsClassifier(n_neighbors=5)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown classifier: {classifier}\")\n",
        "    \n",
        "    # Perform cross-validation\n",
        "    cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
        "    \n",
        "    if metric == 'accuracy':\n",
        "        scores = cross_val_score(clf, X_selected, y, cv=cv, scoring='accuracy')\n",
        "        performance = scores.mean()\n",
        "    elif metric == 'f1':\n",
        "        scores = cross_val_score(clf, X_selected, y, cv=cv, scoring='f1_macro')\n",
        "        performance = scores.mean()\n",
        "    elif metric == 'mcc':\n",
        "        # MCC requires custom scoring\n",
        "        scores = []\n",
        "        for train_idx, val_idx in cv.split(X_selected, y):\n",
        "            clf.fit(X_selected[train_idx], y[train_idx])\n",
        "            y_pred = clf.predict(X_selected[val_idx])\n",
        "            mcc = matthews_corrcoef(y[val_idx], y_pred)\n",
        "            scores.append(mcc)\n",
        "        performance = np.mean(scores)\n",
        "    elif metric == 'roc_auc':\n",
        "        if len(np.unique(y)) == 2:\n",
        "            scores = cross_val_score(clf, X_selected, y, cv=cv, scoring='roc_auc')\n",
        "            performance = scores.mean()\n",
        "        else:\n",
        "            # Multi-class ROC-AUC\n",
        "            scores = cross_val_score(clf, X_selected, y, cv=cv, scoring='roc_auc_ovo')\n",
        "            performance = scores.mean()\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown metric: {metric}\")\n",
        "    \n",
        "    # Compute fitness with optional size penalty\n",
        "    n_selected = len(selected_features)\n",
        "    size_penalty = beta * (n_selected / len(chromosome))\n",
        "    fitness = alpha * performance - size_penalty\n",
        "    \n",
        "    return fitness, performance\n",
        "\n",
        "print(\"Fitness evaluation function defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def differential_mutation(population, F=0.5, strategy='rand/1'):\n",
        "    \"\"\"\n",
        "    Differential mutation operator\n",
        "    \n",
        "    Args:\n",
        "        population: Current population (pop_size, n_features)\n",
        "        F: Scaling factor (default 0.5)\n",
        "        strategy: Mutation strategy ('rand/1', 'best/1', 'rand/2', 'best/2')\n",
        "    \n",
        "    Returns:\n",
        "        mutant_vectors: Mutated vectors\n",
        "    \"\"\"\n",
        "    pop_size, n_features = population.shape\n",
        "    mutant_vectors = np.zeros_like(population)\n",
        "    \n",
        "    # Find best individual (for best-based strategies)\n",
        "    # Note: We'll need fitness values to determine best, so for now use first individual\n",
        "    # This will be updated in the main algorithm\n",
        "    \n",
        "    for i in range(pop_size):\n",
        "        if strategy == 'rand/1':\n",
        "            # v_i = x_r1 + F * (x_r2 - x_r3)\n",
        "            indices = np.random.choice(pop_size, size=3, replace=False)\n",
        "            r1, r2, r3 = indices[0], indices[1], indices[2]\n",
        "            mutant_vectors[i] = population[r1] + F * (population[r2] - population[r3])\n",
        "        elif strategy == 'best/1':\n",
        "            # v_i = x_best + F * (x_r1 - x_r2)\n",
        "            # For now, use first individual as best (will be updated in main algorithm)\n",
        "            best_idx = 0  # Will be passed as parameter in actual implementation\n",
        "            indices = np.random.choice([j for j in range(pop_size) if j != i], size=2, replace=False)\n",
        "            r1, r2 = indices[0], indices[1]\n",
        "            mutant_vectors[i] = population[best_idx] + F * (population[r1] - population[r2])\n",
        "        elif strategy == 'rand/2':\n",
        "            # v_i = x_r1 + F * (x_r2 - x_r3) + F * (x_r4 - x_r5)\n",
        "            indices = np.random.choice(pop_size, size=5, replace=False)\n",
        "            r1, r2, r3, r4, r5 = indices\n",
        "            mutant_vectors[i] = population[r1] + F * (population[r2] - population[r3]) + F * (population[r4] - population[r5])\n",
        "        elif strategy == 'best/2':\n",
        "            # v_i = x_best + F * (x_r1 - x_r2) + F * (x_r3 - x_r4)\n",
        "            best_idx = 0  # Will be passed as parameter\n",
        "            indices = np.random.choice([j for j in range(pop_size) if j != i], size=4, replace=False)\n",
        "            r1, r2, r3, r4 = indices\n",
        "            mutant_vectors[i] = population[best_idx] + F * (population[r1] - population[r2]) + F * (population[r3] - population[r4])\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown strategy: {strategy}\")\n",
        "        \n",
        "        # Clip to bounds [0, 1]\n",
        "        mutant_vectors[i] = np.clip(mutant_vectors[i], 0.0, 1.0)\n",
        "    \n",
        "    return mutant_vectors\n",
        "\n",
        "\n",
        "def binomial_crossover(target, mutant, CR=0.7):\n",
        "    \"\"\"\n",
        "    Binomial crossover operator\n",
        "    \n",
        "    Args:\n",
        "        target: Target vector (parent)\n",
        "        mutant: Mutant vector\n",
        "        CR: Crossover rate (default 0.7)\n",
        "    \n",
        "    Returns:\n",
        "        trial: Trial vector (offspring)\n",
        "    \"\"\"\n",
        "    n_features = len(target)\n",
        "    trial = target.copy()\n",
        "    \n",
        "    # Random index to ensure at least one component from mutant\n",
        "    j_rand = np.random.randint(n_features)\n",
        "    \n",
        "    # Crossover\n",
        "    for j in range(n_features):\n",
        "        if np.random.rand() < CR or j == j_rand:\n",
        "            trial[j] = mutant[j]\n",
        "    \n",
        "    # Clip to bounds\n",
        "    trial = np.clip(trial, 0.0, 1.0)\n",
        "    \n",
        "    return trial\n",
        "\n",
        "\n",
        "def greedy_selection(target, trial, target_fitness, trial_fitness):\n",
        "    \"\"\"\n",
        "    Greedy selection: select the better individual\n",
        "    \n",
        "    Args:\n",
        "        target: Target vector\n",
        "        trial: Trial vector\n",
        "        target_fitness: Fitness of target\n",
        "        trial_fitness: Fitness of trial\n",
        "    \n",
        "    Returns:\n",
        "        selected: Selected vector\n",
        "        selected_fitness: Fitness of selected vector\n",
        "    \"\"\"\n",
        "    if trial_fitness >= target_fitness:\n",
        "        return trial.copy(), trial_fitness\n",
        "    else:\n",
        "        return target.copy(), target_fitness\n",
        "\n",
        "print(\"Differential Evolution operators defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_spiral_radius(spiral_type, theta, a=1.0, b=1.0, k=1.0):\n",
        "    \"\"\"\n",
        "    Compute radial distance for different spiral types\n",
        "    \n",
        "    Args:\n",
        "        spiral_type: Type of spiral ('archimedean', 'logarithmic', 'fermat', 'hyperbolic', 'euler')\n",
        "        theta: Angular displacement\n",
        "        a: Spiral parameter a (default 1.0)\n",
        "        b: Spiral parameter b (default 1.0, used for Archimedean)\n",
        "        k: Spiral parameter k (default 1.0, used for Logarithmic)\n",
        "    \n",
        "    Returns:\n",
        "        r: Radial distance\n",
        "    \"\"\"\n",
        "    if spiral_type == 'archimedean':\n",
        "        # Linear radial growth: r = a + b*theta\n",
        "        r = a + b * theta\n",
        "    elif spiral_type == 'logarithmic':\n",
        "        # Exponential radial growth: r = a * exp(k*theta)\n",
        "        r = a * np.exp(k * theta)\n",
        "    elif spiral_type == 'fermat':\n",
        "        # Square-root expansion: r = a * sqrt(theta)\n",
        "        r = a * np.sqrt(np.maximum(theta, 0))\n",
        "    elif spiral_type == 'hyperbolic':\n",
        "        # Inverse decay: r = a / theta\n",
        "        r = a / np.maximum(theta, 1e-10)  # Avoid division by zero\n",
        "    elif spiral_type == 'euler':\n",
        "        # Euler spiral uses Fresnel integrals, approximate with logarithmic\n",
        "        # For simplicity, we use a logarithmic approximation\n",
        "        r = a * np.exp(k * theta)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown spiral type: {spiral_type}\")\n",
        "    \n",
        "    return r\n",
        "\n",
        "def spiral_update(continuous_vector, elite_vector, spiral_type='archimedean', \n",
        "                  r_factor=0.5, theta_factor=2*np.pi, a=1.0, b=1.0, k=1.0):\n",
        "    \"\"\"\n",
        "    Apply spiral-based update to a continuous vector\n",
        "    \n",
        "    Generic spiral update: z = x* + R(r,θ)(x - x*)\n",
        "    where x* is the elite solution and x is the current vector\n",
        "    \n",
        "    Args:\n",
        "        continuous_vector: Current continuous vector (n_features,)\n",
        "        elite_vector: Elite (best) continuous vector (n_features,)\n",
        "        spiral_type: Type of spiral ('archimedean', 'logarithmic', 'fermat', 'hyperbolic', 'euler')\n",
        "        r_factor: Radial scaling factor (default 0.5)\n",
        "        theta_factor: Angular displacement factor (default 2π)\n",
        "        a, b, k: Spiral parameters\n",
        "    \n",
        "    Returns:\n",
        "        new_vector: Updated continuous vector\n",
        "    \"\"\"\n",
        "    n_features = len(continuous_vector)\n",
        "    \n",
        "    # Step 1: Compute spiral parameters\n",
        "    # Generate random angular displacement for each dimension\n",
        "    theta = np.random.uniform(0, theta_factor, size=n_features)\n",
        "    \n",
        "    # Compute radial scaling for each dimension\n",
        "    r = compute_spiral_radius(spiral_type, theta, a=a, b=b, k=k)\n",
        "    r = r_factor * r  # Scale by r_factor\n",
        "    \n",
        "    # Step 2: Apply spiral update: z = x* + R(r,θ)(x - x*)\n",
        "    # R(r,θ) represents rotation and scaling\n",
        "    # Compute rotation-scaling factor\n",
        "    R = r * np.cos(theta) + (1 - r) * np.sin(theta)\n",
        "    R = np.clip(R, 0, 1)  # Ensure R is in [0,1]\n",
        "    \n",
        "    # Apply spiral transformation\n",
        "    z = elite_vector + R * (continuous_vector - elite_vector)\n",
        "    \n",
        "    # Step 3: Clamp z to [0,1]\n",
        "    z = np.clip(z, 0.0, 1.0)\n",
        "    \n",
        "    return z\n",
        "\n",
        "def apply_spiral_enhancement(population, elite_vector, elite_fitness, \n",
        "                            fitness_values, spiral_type='archimedean',\n",
        "                            spiral_rate=0.3, r_factor=0.5, theta_factor=2*np.pi,\n",
        "                            a=1.0, b=1.0, k=1.0):\n",
        "    \"\"\"\n",
        "    Apply spiral enhancement to a portion of the population\n",
        "    \n",
        "    Args:\n",
        "        population: Current population\n",
        "        elite_vector: Best continuous vector (elite solution)\n",
        "        elite_fitness: Fitness of elite solution\n",
        "        fitness_values: Fitness values for all individuals\n",
        "        spiral_type: Type of spiral to use\n",
        "        spiral_rate: Fraction of population to enhance with spiral (default 0.3)\n",
        "        r_factor: Radial scaling factor\n",
        "        theta_factor: Angular displacement factor\n",
        "        a, b, k: Spiral parameters\n",
        "    \n",
        "    Returns:\n",
        "        enhanced_population: Population with spiral-enhanced individuals\n",
        "    \"\"\"\n",
        "    enhanced_population = population.copy()\n",
        "    pop_size = len(population)\n",
        "    \n",
        "    # Select individuals to enhance (excluding the elite itself)\n",
        "    # We enhance individuals that are not the elite but have reasonable fitness\n",
        "    n_to_enhance = max(1, int(spiral_rate * pop_size))\n",
        "    \n",
        "    # Get indices sorted by fitness (excluding elite)\n",
        "    elite_idx = np.argmax(fitness_values)\n",
        "    candidate_indices = [i for i in range(pop_size) if i != elite_idx]\n",
        "    \n",
        "    # Select top candidates for enhancement (those with good but not best fitness)\n",
        "    if len(candidate_indices) > 0:\n",
        "        candidate_fitness = [fitness_values[i] for i in candidate_indices]\n",
        "        sorted_candidates = sorted(zip(candidate_fitness, candidate_indices), reverse=True)\n",
        "        selected_indices = [idx for _, idx in sorted_candidates[:n_to_enhance]]\n",
        "        \n",
        "        # Apply spiral enhancement to selected individuals\n",
        "        for idx in selected_indices:\n",
        "            enhanced_population[idx] = spiral_update(\n",
        "                population[idx], \n",
        "                elite_vector,\n",
        "                spiral_type=spiral_type,\n",
        "                r_factor=r_factor,\n",
        "                theta_factor=theta_factor,\n",
        "                a=a, b=b, k=k\n",
        "            )\n",
        "    \n",
        "    return enhanced_population\n",
        "\n",
        "print(\"Spiral-based enhancement operators defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.5 Differential Evolution Main Class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DifferentialEvolutionFeatureSelection:\n",
        "    \"\"\"\n",
        "    Differential Evolution for Feature Selection with Spiral-Based Enhancement\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, X, y, pop_size=50, n_generations=50, F=0.5, CR=0.7,\n",
        "                 mutation_strategy='rand/1', classifier='rf', metric='accuracy',\n",
        "                 alpha=1.0, beta=0.0, cv_folds=5, threshold=0.5,\n",
        "                 use_spiral=False, spiral_type='archimedean', spiral_rate=0.3,\n",
        "                 r_factor=0.5, theta_factor=2*np.pi, spiral_a=1.0, spiral_b=1.0, spiral_k=1.0):\n",
        "        \"\"\"\n",
        "        Initialize DE for feature selection\n",
        "        \n",
        "        Args:\n",
        "            X: Feature matrix\n",
        "            y: Target vector\n",
        "            pop_size: Population size\n",
        "            n_generations: Number of generations\n",
        "            F: Scaling factor for mutation (default 0.5)\n",
        "            CR: Crossover rate (default 0.7)\n",
        "            mutation_strategy: Mutation strategy ('rand/1', 'best/1', 'rand/2', 'best/2')\n",
        "            classifier: Classifier type ('rf', 'svm', 'knn')\n",
        "            metric: Performance metric ('accuracy', 'f1', 'mcc', 'roc_auc')\n",
        "            alpha: Weight for performance term\n",
        "            beta: Weight for size penalty term\n",
        "            cv_folds: Number of CV folds\n",
        "            threshold: Threshold for converting continuous to binary (default 0.5)\n",
        "            use_spiral: Whether to use spiral-based enhancement (default False)\n",
        "            spiral_type: Type of spiral ('archimedean', 'logarithmic', 'fermat', 'hyperbolic', 'euler')\n",
        "            spiral_rate: Fraction of population to enhance with spiral (default 0.3)\n",
        "            r_factor: Radial scaling factor for spiral (default 0.5)\n",
        "            theta_factor: Angular displacement factor for spiral (default 2π)\n",
        "            spiral_a: Spiral parameter a (default 1.0)\n",
        "            spiral_b: Spiral parameter b (default 1.0, used for Archimedean)\n",
        "            spiral_k: Spiral parameter k (default 1.0, used for Logarithmic)\n",
        "        \"\"\"\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.n_features = X.shape[1]\n",
        "        self.pop_size = pop_size\n",
        "        self.n_generations = n_generations\n",
        "        self.F = F\n",
        "        self.CR = CR\n",
        "        self.mutation_strategy = mutation_strategy\n",
        "        self.classifier = classifier\n",
        "        self.metric = metric\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.cv_folds = cv_folds\n",
        "        self.threshold = threshold\n",
        "        \n",
        "        # Spiral enhancement parameters\n",
        "        self.use_spiral = use_spiral\n",
        "        self.spiral_type = spiral_type\n",
        "        self.spiral_rate = spiral_rate\n",
        "        self.r_factor = r_factor\n",
        "        self.theta_factor = theta_factor\n",
        "        self.spiral_a = spiral_a\n",
        "        self.spiral_b = spiral_b\n",
        "        self.spiral_k = spiral_k\n",
        "        \n",
        "        # History tracking\n",
        "        self.history = {\n",
        "            'best_fitness': [],\n",
        "            'avg_fitness': [],\n",
        "            'worst_fitness': [],\n",
        "            'best_performance': [],\n",
        "            'avg_performance': [],\n",
        "            'best_n_features': [],\n",
        "            'avg_n_features': [],\n",
        "            'diversity': [],\n",
        "            'best_vector': None\n",
        "        }\n",
        "    \n",
        "    def compute_diversity(self, population):\n",
        "        \"\"\"\n",
        "        Compute population diversity as average Euclidean distance\n",
        "        \"\"\"\n",
        "        pop_size = len(population)\n",
        "        if pop_size < 2:\n",
        "            return 0.0\n",
        "        \n",
        "        total_distance = 0\n",
        "        n_pairs = 0\n",
        "        \n",
        "        for i in range(pop_size):\n",
        "            for j in range(i + 1, pop_size):\n",
        "                # Euclidean distance\n",
        "                distance = np.linalg.norm(population[i] - population[j])\n",
        "                total_distance += distance\n",
        "                n_pairs += 1\n",
        "        \n",
        "        return total_distance / n_pairs if n_pairs > 0 else 0.0\n",
        "    \n",
        "    def differential_mutation_with_best(self, population, best_idx):\n",
        "        \"\"\"\n",
        "        Differential mutation with best individual support\n",
        "        \"\"\"\n",
        "        pop_size, n_features = population.shape\n",
        "        mutant_vectors = np.zeros_like(population)\n",
        "        \n",
        "        for i in range(pop_size):\n",
        "            if self.mutation_strategy == 'rand/1':\n",
        "                # v_i = x_r1 + F * (x_r2 - x_r3)\n",
        "                indices = np.random.choice(pop_size, size=3, replace=False)\n",
        "                r1, r2, r3 = indices[0], indices[1], indices[2]\n",
        "                mutant_vectors[i] = population[r1] + self.F * (population[r2] - population[r3])\n",
        "            elif self.mutation_strategy == 'best/1':\n",
        "                # v_i = x_best + F * (x_r1 - x_r2)\n",
        "                indices = np.random.choice([j for j in range(pop_size) if j != i], size=2, replace=False)\n",
        "                r1, r2 = indices[0], indices[1]\n",
        "                mutant_vectors[i] = population[best_idx] + self.F * (population[r1] - population[r2])\n",
        "            elif self.mutation_strategy == 'rand/2':\n",
        "                # v_i = x_r1 + F * (x_r2 - x_r3) + F * (x_r4 - x_r5)\n",
        "                indices = np.random.choice(pop_size, size=5, replace=False)\n",
        "                r1, r2, r3, r4, r5 = indices\n",
        "                mutant_vectors[i] = population[r1] + self.F * (population[r2] - population[r3]) + self.F * (population[r4] - population[r5])\n",
        "            elif self.mutation_strategy == 'best/2':\n",
        "                # v_i = x_best + F * (x_r1 - x_r2) + F * (x_r3 - x_r4)\n",
        "                indices = np.random.choice([j for j in range(pop_size) if j != i], size=4, replace=False)\n",
        "                r1, r2, r3, r4 = indices\n",
        "                mutant_vectors[i] = population[best_idx] + self.F * (population[r1] - population[r2]) + self.F * (population[r3] - population[r4])\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown strategy: {self.mutation_strategy}\")\n",
        "            \n",
        "            # Clip to bounds [0, 1]\n",
        "            mutant_vectors[i] = np.clip(mutant_vectors[i], 0.0, 1.0)\n",
        "        \n",
        "        return mutant_vectors\n",
        "    \n",
        "    def run(self):\n",
        "        \"\"\"\n",
        "        Run the differential evolution algorithm\n",
        "        \"\"\"\n",
        "        print(f\"Starting Differential Evolution for Feature Selection\")\n",
        "        print(f\"  Population size: {self.pop_size}\")\n",
        "        print(f\"  Generations: {self.n_generations}\")\n",
        "        print(f\"  Scaling factor (F): {self.F}\")\n",
        "        print(f\"  Crossover rate (CR): {self.CR}\")\n",
        "        print(f\"  Mutation strategy: {self.mutation_strategy}\")\n",
        "        print(f\"  Classifier: {self.classifier}\")\n",
        "        print(f\"  Metric: {self.metric}\")\n",
        "        if self.use_spiral:\n",
        "            print(f\"  Spiral Enhancement: ENABLED ({self.spiral_type})\")\n",
        "            print(f\"    Spiral rate: {self.spiral_rate}, r_factor: {self.r_factor}\")\n",
        "        else:\n",
        "            print(f\"  Spiral Enhancement: DISABLED\")\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        \n",
        "        # Initialize population\n",
        "        population = initialize_population(self.pop_size, self.n_features)\n",
        "        \n",
        "        # Evaluate initial population\n",
        "        fitness_values = np.zeros(self.pop_size)\n",
        "        performance_values = np.zeros(self.pop_size)\n",
        "        \n",
        "        print(\"Evaluating initial population...\")\n",
        "        for i in range(self.pop_size):\n",
        "            fitness_values[i], performance_values[i] = evaluate_fitness(\n",
        "                population[i], self.X, self.y, \n",
        "                classifier=self.classifier, \n",
        "                metric=self.metric,\n",
        "                alpha=self.alpha, \n",
        "                beta=self.beta,\n",
        "                cv_folds=self.cv_folds,\n",
        "                threshold=self.threshold\n",
        "            )\n",
        "            if (i + 1) % 10 == 0:\n",
        "                print(f\"  Evaluated {i+1}/{self.pop_size} individuals\")\n",
        "        \n",
        "        # Find best solution\n",
        "        best_idx = np.argmax(fitness_values)\n",
        "        best_vector = population[best_idx].copy()\n",
        "        best_fitness = fitness_values[best_idx]\n",
        "        best_binary = continuous_to_binary(best_vector, threshold=self.threshold)\n",
        "        \n",
        "        # Record initial statistics\n",
        "        self.history['best_fitness'].append(best_fitness)\n",
        "        self.history['avg_fitness'].append(np.mean(fitness_values))\n",
        "        self.history['worst_fitness'].append(np.min(fitness_values))\n",
        "        self.history['best_performance'].append(performance_values[best_idx])\n",
        "        self.history['avg_performance'].append(np.mean(performance_values))\n",
        "        self.history['best_n_features'].append(np.sum(best_binary))\n",
        "        self.history['avg_n_features'].append(np.mean([np.sum(continuous_to_binary(p, threshold=self.threshold)) for p in population]))\n",
        "        self.history['diversity'].append(self.compute_diversity(population))\n",
        "        \n",
        "        print(f\"\\nGeneration 0: Best fitness = {best_fitness:.6f}, \"\n",
        "              f\"Performance = {performance_values[best_idx]:.6f}, \"\n",
        "              f\"Features = {np.sum(best_binary)}\")\n",
        "        \n",
        "        # Main evolution loop\n",
        "        for gen in range(1, self.n_generations + 1):\n",
        "            # Create new population\n",
        "            new_population = population.copy()\n",
        "            new_fitness = fitness_values.copy()\n",
        "            new_performance = performance_values.copy()\n",
        "            \n",
        "            # For each individual in population\n",
        "            for i in range(self.pop_size):\n",
        "                # Mutation\n",
        "                mutant = self.differential_mutation_with_best(population, best_idx)[i]\n",
        "                \n",
        "                # Crossover\n",
        "                trial = binomial_crossover(population[i], mutant, CR=self.CR)\n",
        "                \n",
        "                # Evaluate trial\n",
        "                trial_fitness, trial_performance = evaluate_fitness(\n",
        "                    trial, self.X, self.y,\n",
        "                    classifier=self.classifier,\n",
        "                    metric=self.metric,\n",
        "                    alpha=self.alpha,\n",
        "                    beta=self.beta,\n",
        "                    cv_folds=self.cv_folds,\n",
        "                    threshold=self.threshold\n",
        "                )\n",
        "                \n",
        "                # Selection\n",
        "                if trial_fitness >= fitness_values[i]:\n",
        "                    new_population[i] = trial\n",
        "                    new_fitness[i] = trial_fitness\n",
        "                    new_performance[i] = trial_performance\n",
        "                    \n",
        "                    # Update best if improved\n",
        "                    if trial_fitness > best_fitness:\n",
        "                        best_vector = trial.copy()\n",
        "                        best_fitness = trial_fitness\n",
        "                        best_idx = i\n",
        "            \n",
        "            # Update population\n",
        "            population = new_population\n",
        "            fitness_values = new_fitness\n",
        "            performance_values = new_performance\n",
        "            \n",
        "            # Apply spiral-based enhancement if enabled\n",
        "            if self.use_spiral:\n",
        "                # Store population before spiral enhancement for comparison\n",
        "                population_before_spiral = population.copy()\n",
        "                \n",
        "                # Apply spiral enhancement to a portion of the population\n",
        "                population = apply_spiral_enhancement(\n",
        "                    population,\n",
        "                    best_vector,  # Elite vector\n",
        "                    best_fitness,  # Elite fitness\n",
        "                    fitness_values,\n",
        "                    spiral_type=self.spiral_type,\n",
        "                    spiral_rate=self.spiral_rate,\n",
        "                    r_factor=self.r_factor,\n",
        "                    theta_factor=self.theta_factor,\n",
        "                    a=self.spiral_a,\n",
        "                    b=self.spiral_b,\n",
        "                    k=self.spiral_k\n",
        "                )\n",
        "                \n",
        "                # Re-evaluate enhanced individuals (only those that changed)\n",
        "                for i in range(self.pop_size):\n",
        "                    if not np.allclose(population[i], population_before_spiral[i], atol=1e-10):\n",
        "                        fitness_values[i], performance_values[i] = evaluate_fitness(\n",
        "                            population[i], self.X, self.y,\n",
        "                            classifier=self.classifier,\n",
        "                            metric=self.metric,\n",
        "                            alpha=self.alpha,\n",
        "                            beta=self.beta,\n",
        "                            cv_folds=self.cv_folds,\n",
        "                            threshold=self.threshold\n",
        "                        )\n",
        "                \n",
        "                # Update best solution after spiral enhancement\n",
        "                current_best_idx = np.argmax(fitness_values)\n",
        "                if fitness_values[current_best_idx] > best_fitness:\n",
        "                    best_vector = population[current_best_idx].copy()\n",
        "                    best_fitness = fitness_values[current_best_idx]\n",
        "                    best_idx = current_best_idx\n",
        "            \n",
        "            # Convert best to binary for statistics\n",
        "            best_binary = continuous_to_binary(best_vector, threshold=self.threshold)\n",
        "            \n",
        "            # Record statistics\n",
        "            self.history['best_fitness'].append(best_fitness)\n",
        "            self.history['avg_fitness'].append(np.mean(fitness_values))\n",
        "            self.history['worst_fitness'].append(np.min(fitness_values))\n",
        "            self.history['best_performance'].append(performance_values[best_idx])\n",
        "            self.history['avg_performance'].append(np.mean(performance_values))\n",
        "            self.history['best_n_features'].append(np.sum(best_binary))\n",
        "            self.history['avg_n_features'].append(np.mean([np.sum(continuous_to_binary(p, threshold=self.threshold)) for p in population]))\n",
        "            self.history['diversity'].append(self.compute_diversity(population))\n",
        "            \n",
        "            # Print progress\n",
        "            if gen % 5 == 0 or gen == self.n_generations:\n",
        "                print(f\"Generation {gen}: Best fitness = {best_fitness:.6f}, \"\n",
        "                      f\"Performance = {performance_values[best_idx]:.6f}, \"\n",
        "                      f\"Features = {np.sum(best_binary)}, \"\n",
        "                      f\"Diversity = {self.history['diversity'][-1]:.2f}\")\n",
        "        \n",
        "        # Store best solution (convert to binary)\n",
        "        self.history['best_vector'] = best_vector\n",
        "        best_chromosome = continuous_to_binary(best_vector, threshold=self.threshold)\n",
        "        \n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Evolution completed!\")\n",
        "        print(f\"Best fitness: {best_fitness:.6f}\")\n",
        "        print(f\"Best performance: {performance_values[best_idx]:.6f}\")\n",
        "        print(f\"Selected features: {np.sum(best_chromosome)}/{self.n_features}\")\n",
        "        \n",
        "        return best_chromosome, best_fitness\n",
        "\n",
        "print(\"Differential Evolution class defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define all spiral types to test (including 'standard' for comparison)\n",
        "SPIRAL_TYPES = ['standard', 'archimedean', 'logarithmic', 'fermat', 'hyperbolic', 'euler']\n",
        "\n",
        "# Spiral enhancement parameters (will be used when spiral_type != 'standard')\n",
        "spiral_params = {\n",
        "    'spiral_rate': 0.3,  # Fraction of population to enhance with spiral (30%)\n",
        "    'r_factor': 0.5,  # Radial scaling factor\n",
        "    'theta_factor': 2*np.pi,  # Angular displacement factor\n",
        "    'spiral_a': 1.0,  # Spiral parameter a\n",
        "    'spiral_b': 1.0,  # Spiral parameter b (used for Archimedean)\n",
        "    'spiral_k': 1.0  # Spiral parameter k (used for Logarithmic)\n",
        "}\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"SPIRAL TYPES CONFIGURATION\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Spiral types to test: {SPIRAL_TYPES}\")\n",
        "print(f\"  - 'standard': Standard DE without spiral enhancement\")\n",
        "print(f\"  - 'archimedean': Linear radial growth (r = a + b*θ)\")\n",
        "print(f\"  - 'logarithmic': Exponential radial growth (r = a*e^(k*θ))\")\n",
        "print(f\"  - 'fermat': Square-root expansion (r = a*√θ)\")\n",
        "print(f\"  - 'hyperbolic': Inverse decay (r = a/θ)\")\n",
        "print(f\"  - 'euler': Euler spiral (approximated with logarithmic)\")\n",
        "print(f\"\\nSpiral parameters: {spiral_params}\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SPIRAL ENHANCEMENT CONFIGURATION - AUTOMATIC ALL SPIRAL TYPES\n",
        "# ============================================================================\n",
        "# AUTOMATICALLY RUNS ALL SPIRAL TYPES IN A LOOP\n",
        "# This will test: 'standard', 'archimedean', 'logarithmic', 'fermat', 'hyperbolic', 'euler'\n",
        "\n",
        "# Define all spiral types to test (including 'standard' for comparison)\n",
        "SPIRAL_TYPES = ['standard', 'archimedean', 'logarithmic', 'fermat', 'hyperbolic', 'euler']\n",
        "\n",
        "# Spiral parameters (used for all non-standard spiral types)\n",
        "spiral_params = {\n",
        "    'spiral_rate': 0.3,  # Fraction of population to enhance with spiral (30%)\n",
        "    'r_factor': 0.5,  # Radial scaling factor\n",
        "    'theta_factor': 2*np.pi,  # Angular displacement factor\n",
        "    'spiral_a': 1.0,  # Spiral parameter a\n",
        "    'spiral_b': 1.0,  # Spiral parameter b (used for Archimedean)\n",
        "    'spiral_k': 1.0  # Spiral parameter k (used for Logarithmic)\n",
        "}\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"SPIRAL ENHANCEMENT: AUTOMATIC MODE - ALL SPIRAL TYPES\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Will automatically test {len(SPIRAL_TYPES)} spiral types:\")\n",
        "for st in SPIRAL_TYPES:\n",
        "    print(f\"  - {st.upper()}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Configure DE parameters (base parameters, classifier will be set in loop)\n",
        "de_base_params = {\n",
        "    'pop_size': 20,\n",
        "    'n_generations': 10,\n",
        "    'F': 0.5,  # Scaling factor\n",
        "    'CR': 0.7,  # Crossover rate\n",
        "    'mutation_strategy': 'rand/1',  # 'rand/1', 'best/1', 'rand/2', 'best/2'\n",
        "    'metric': 'accuracy',  # 'accuracy', 'f1', 'mcc', 'roc_auc'\n",
        "    'alpha': 1.0,  # Performance weight\n",
        "    'beta': 0.0,  # Size penalty weight (0 = no penalty)\n",
        "    'cv_folds': 5,\n",
        "    'threshold': 0.5  # Threshold for continuous to binary conversion\n",
        "}\n",
        "\n",
        "# Define all classifiers to test\n",
        "CLASSIFIERS = ['rf', 'svm', 'knn']\n",
        "\n",
        "# Storage for all results across datasets, models, and spiral types\n",
        "# Structure: all_results[dataset_name][classifier_name][spiral_type] = {...}\n",
        "all_results = {}\n",
        "\n",
        "baseline_results = {}\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"STEP 1: BASELINE EVALUATION - ALL CLASSIFIERS ON ALL FEATURES\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Datasets: {len(BENCHMARK_DATASETS)}\")\n",
        "print(f\"Classifiers: {CLASSIFIERS}\")\n",
        "print(f\"Total baseline evaluations: {len(BENCHMARK_DATASETS) * len(CLASSIFIERS)}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Preprocessing: Evaluate all classifiers on all features for all datasets\n",
        "import time\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for dataset_name in BENCHMARK_DATASETS:\n",
        "    print(f\"\\n{'-'*80}\")\n",
        "    print(f\"Baseline Evaluation - Dataset: {dataset_name.upper()}\")\n",
        "    print(f\"{'-'*80}\")\n",
        "    \n",
        "    try:\n",
        "        # Load dataset\n",
        "        X, y, feature_names = load_benchmark_dataset(dataset_name)\n",
        "        n_features = X.shape[1]\n",
        "        \n",
        "        # Initialize baseline results dictionary for this dataset\n",
        "        baseline_results[dataset_name] = {}\n",
        "        \n",
        "        # Evaluate each classifier on all features\n",
        "        for classifier_name in CLASSIFIERS:\n",
        "            try:\n",
        "                print(f\"  Evaluating {classifier_name.upper()} on all features...\", end=' ')\n",
        "                \n",
        "                # Initialize classifier\n",
        "                if classifier_name == 'rf':\n",
        "                    clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "                elif classifier_name == 'svm':\n",
        "                    clf = SVC(kernel='rbf', random_state=42, probability=True)\n",
        "                elif classifier_name == 'knn':\n",
        "                    clf = KNeighborsClassifier(n_neighbors=5)\n",
        "                \n",
        "                # Evaluate on all features\n",
        "                baseline_start = time.time()\n",
        "                scores_all = cross_val_score(clf, X, y, cv=cv, scoring='accuracy')\n",
        "                baseline_time = time.time() - baseline_start\n",
        "                \n",
        "                # Store baseline results\n",
        "                baseline_results[dataset_name][classifier_name] = {\n",
        "                    'X': X,\n",
        "                    'y': y,\n",
        "                    'feature_names': feature_names,\n",
        "                    'n_features': n_features,\n",
        "                    'scores_all': scores_all,\n",
        "                    'performance_all': scores_all.mean(),\n",
        "                    'performance_std_all': scores_all.std(),\n",
        "                    'baseline_time': baseline_time\n",
        "                }\n",
        "                \n",
        "                print(f\" Performance: {scores_all.mean():.4f} ± {scores_all.std():.4f} (Time: {baseline_time:.2f}s)\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"✗ Error: {str(e)}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "                continue\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\\n✗ Error loading dataset {dataset_name}: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        continue\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"STEP 1 COMPLETED: Baseline evaluation finished\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STEP 2: RUNNING DIFFERENTIAL EVOLUTION ON ALL BENCHMARK DATASETS AND MODELS\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Datasets: {len(BENCHMARK_DATASETS)}\")\n",
        "print(f\"Classifiers: {CLASSIFIERS}\")\n",
        "print(f\"Spiral Types: {SPIRAL_TYPES}\")\n",
        "print(f\"Total combinations: {len(BENCHMARK_DATASETS) * len(CLASSIFIERS) * len(SPIRAL_TYPES)}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Loop through all spiral types\n",
        "for spiral_type in SPIRAL_TYPES:\n",
        "    print(f\"\\n{'#'*80}\")\n",
        "    print(f\"# SPIRAL TYPE: {spiral_type.upper()}\")\n",
        "    print(f\"{'#'*80}\")\n",
        "    \n",
        "    # Determine if we should use spiral enhancement\n",
        "    use_spiral = (spiral_type != 'standard')\n",
        "    \n",
        "    # Loop through all benchmark datasets\n",
        "    for dataset_name in BENCHMARK_DATASETS:\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"Processing Dataset: {dataset_name.upper()}\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        try:\n",
        "            # Load dataset\n",
        "            X, y, feature_names = load_benchmark_dataset(dataset_name)\n",
        "            n_features = X.shape[1]\n",
        "\n",
        "            # Initialize results dictionary for this dataset if not exists\n",
        "            if dataset_name not in all_results:\n",
        "                all_results[dataset_name] = {}\n",
        "\n",
        "            # Loop through all classifiers\n",
        "            for classifier_name in CLASSIFIERS:\n",
        "                print(f\"\\n{'-'*80}\")\n",
        "                print(f\"  Classifier: {classifier_name.upper()} | Spiral: {spiral_type.upper()}\")\n",
        "                print(f\"{'-'*80}\")\n",
        "\n",
        "                try:\n",
        "                    # Start timing\n",
        "                    import time\n",
        "                    start_time = time.time()\n",
        "\n",
        "                    # Create DE parameters with current classifier and spiral settings\n",
        "                    de_params = de_base_params.copy()\n",
        "                    de_params['classifier'] = classifier_name\n",
        "                    de_params['use_spiral'] = use_spiral\n",
        "\n",
        "                    # Add spiral-specific parameters if using spiral\n",
        "                    if use_spiral:\n",
        "                        de_params['spiral_type'] = spiral_type\n",
        "                        de_params['spiral_rate'] = spiral_params['spiral_rate']\n",
        "                        de_params['r_factor'] = spiral_params['r_factor']\n",
        "                        de_params['theta_factor'] = spiral_params['theta_factor']\n",
        "                        de_params['spiral_a'] = spiral_params['spiral_a']\n",
        "                        de_params['spiral_b'] = spiral_params['spiral_b']\n",
        "                        de_params['spiral_k'] = spiral_params['spiral_k']\n",
        "\n",
        "                    # Initialize and run DE\n",
        "                    de = DifferentialEvolutionFeatureSelection(X, y, **de_params)\n",
        "                    best_chromosome, best_fitness = de.run()\n",
        "\n",
        "                    # Get selected features\n",
        "                    selected_features = np.where(best_chromosome == 1)[0]\n",
        "                    selected_features_idx = np.where(best_chromosome == 1)[0]\n",
        "                    X_selected = X[:, selected_features_idx]\n",
        "\n",
        "                    # End timing\n",
        "                    de_time = time.time() - start_time\n",
        "\n",
        "                    # Evaluate performance with selected features using the same classifier\n",
        "                    if classifier_name == 'rf':\n",
        "                        clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "                    elif classifier_name == 'svm':\n",
        "                        clf = SVC(kernel='rbf', random_state=42, probability=True)\n",
        "                    elif classifier_name == 'knn':\n",
        "                        clf = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "                    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "                    # Time the evaluation of selected features\n",
        "                    eval_start = time.time()\n",
        "                    scores_selected = cross_val_score(clf, X_selected, y, cv=cv, scoring='accuracy')\n",
        "                    eval_time = time.time() - eval_start\n",
        "\n",
        "                    # Get baseline results (all features) from preprocessing step\n",
        "                    baseline_data = baseline_results[dataset_name][classifier_name]\n",
        "                    scores_all = baseline_data['scores_all']\n",
        "\n",
        "                    total_time = de_time + eval_time\n",
        "\n",
        "                    # Initialize classifier dictionary if not exists\n",
        "                    if classifier_name not in all_results[dataset_name]:\n",
        "                        all_results[dataset_name][classifier_name] = {}\n",
        "\n",
        "                    # Store results with spiral_type\n",
        "                    all_results[dataset_name][classifier_name][spiral_type] = {\n",
        "                        'X': X,\n",
        "                        'y': y,\n",
        "                        'feature_names': feature_names,\n",
        "                        'n_features': n_features,\n",
        "                        'de': de,\n",
        "                        'best_chromosome': best_chromosome,\n",
        "                        'best_fitness': best_fitness,\n",
        "                        'selected_features': selected_features,\n",
        "                        'selected_features_idx': selected_features_idx,\n",
        "                        'scores_selected': scores_selected,\n",
        "                        'scores_all': scores_all,  # From baseline evaluation\n",
        "                        'performance_selected': scores_selected.mean(),\n",
        "                        'performance_all': scores_all.mean(),  # From baseline evaluation\n",
        "                        'n_selected': len(selected_features),\n",
        "                        'reduction_ratio': len(selected_features) / n_features,\n",
        "                        'de_time': de_time,\n",
        "                        'eval_time': eval_time,\n",
        "                        'total_time': total_time,\n",
        "                        'baseline_time': baseline_data['baseline_time']  # Store baseline evaluation time\n",
        "                    }\n",
        "\n",
        "                    print(f\"\\n  Completed {dataset_name} with {classifier_name}\")\n",
        "                    print(f\"    Selected: {len(selected_features)}/{n_features} features ({len(selected_features)/n_features*100:.1f}%)\")\n",
        "                    print(f\"    Performance (Selected): {scores_selected.mean():.4f} ± {scores_selected.std():.4f}\")\n",
        "                    print(f\"    Performance (All): {scores_all.mean():.4f} ± {scores_all.std():.4f}\")\n",
        "                    print(f\"    DE Time: {de_time:.2f}s, Eval Time: {eval_time:.2f}s, Total: {total_time:.2f}s\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"\\n  ✗ Error processing {dataset_name} with {classifier_name}: {str(e)}\")\n",
        "                    import traceback\n",
        "                    traceback.print_exc()\n",
        "                    continue\n",
        "\n",
        "            print(f\"\\n✓ Completed all classifiers for {dataset_name}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n✗ Error loading dataset {dataset_name}: {str(e)}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "\n",
        "# Summary\n",
        "total_combinations = sum(len(all_results[ds]) for ds in all_results.keys())\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"COMPLETED PROCESSING\")\n",
        "print(f\"  Successful combinations: {total_combinations}/{len(BENCHMARK_DATASETS) * len(CLASSIFIERS)}\")\n",
        "print(f\"  Datasets processed: {len(all_results)}/{len(BENCHMARK_DATASETS)}\")\n",
        "print(f\"{'='*80}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Comprehensive Visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compare_with_all_features(X, y, best_chromosome, classifier='rf', cv_folds=5):\n",
        "    \"\"\"\n",
        "    Compare performance with selected features vs all features\n",
        "    \"\"\"\n",
        "    # Evaluate with selected features\n",
        "    selected_features = np.where(best_chromosome == 1)[0]\n",
        "    X_selected = X[:, selected_features]\n",
        "    \n",
        "    # Initialize classifier\n",
        "    if classifier == 'rf':\n",
        "        clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "    elif classifier == 'svm':\n",
        "        clf = SVC(kernel='rbf', random_state=42, probability=True)\n",
        "    elif classifier == 'knn':\n",
        "        clf = KNeighborsClassifier(n_neighbors=5)\n",
        "    \n",
        "    # Cross-validation with selected features\n",
        "    cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
        "    scores_selected = cross_val_score(clf, X_selected, y, cv=cv, scoring='accuracy')\n",
        "    \n",
        "    # Cross-validation with all features\n",
        "    scores_all = cross_val_score(clf, X, y, cv=cv, scoring='accuracy')\n",
        "    \n",
        "    # Create comparison plot\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "    \n",
        "    # Plot 1: Box plot comparison\n",
        "    data_to_plot = [scores_all, scores_selected]\n",
        "    bp = axes[0].boxplot(data_to_plot, labels=['All Features', f'Selected ({len(selected_features)})'], \n",
        "                         patch_artist=True)\n",
        "    bp['boxes'][0].set_facecolor('lightblue')\n",
        "    bp['boxes'][1].set_facecolor('lightgreen')\n",
        "    axes[0].set_ylabel('Accuracy', fontsize=12)\n",
        "    axes[0].set_title('Performance Comparison: All Features vs Selected Features', \n",
        "                      fontsize=14, fontweight='bold')\n",
        "    axes[0].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "    means = [scores_all.mean(), scores_selected.mean()]\n",
        "    stds = [scores_all.std(), scores_selected.std()]\n",
        "\n",
        "    bars = axes[1].bar(\n",
        "    ['All Features', f'Selected ({len(selected_features)})'],\n",
        "    means, yerr=stds, capsize=10,\n",
        "    color=['lightblue', 'lightgreen'],\n",
        "    edgecolor='black', linewidth=2)\n",
        "\n",
        "    for bar in bars:\n",
        "        bar.set_alpha(0.8)\n",
        "\n",
        "    axes[1].set_ylabel('Mean Accuracy ± Std Dev', fontsize=12)\n",
        "    axes[1].set_title('Mean Performance Comparison', fontsize=14, fontweight='bold')\n",
        "    axes[1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "    low = min(means) - 0.01\n",
        "    high = max(means) + 0.01\n",
        "    axes[1].set_ylim([low, high])\n",
        "\n",
        "    # labels\n",
        "    for i, (mean, std) in enumerate(zip(means, stds)):\n",
        "        axes[1].text(i, mean + std + 0.002, f'{mean:.4f}±{std:.4f}',\n",
        "                     ha='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print statistics\n",
        "    total = X.shape[1]\n",
        "    selected = np.sum(best_chromosome)\n",
        "    removed = total - selected\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"Performance Comparison:\")\n",
        "    print(f\"  All Features: {scores_all.mean():.6f} ± {scores_all.std():.6f}\")\n",
        "    print(f\"  Selected Features ({len(selected_features)}): {scores_selected.mean():.6f} ± {scores_selected.std():.6f}\")\n",
        "    print(f\"  Feature Reduction: {removed}/{X.shape[1]} = { removed /X.shape[1]*100:.1f}%\")\n",
        "    print(f\"  Performance Change: {(scores_selected.mean() - scores_all.mean())*100:+.2f}%\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    return scores_all, scores_selected\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_summary_statistics(de, best_chromosome, feature_names):\n",
        "    \"\"\"\n",
        "    Print comprehensive summary statistics\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"DIFFERENTIAL EVOLUTION FEATURE SELECTION - SUMMARY STATISTICS\")\n",
        "    print(f\"{'='*70}\")\n",
        "    \n",
        "    print(f\"\\n Algorithm Configuration:\")\n",
        "    print(f\"  Population Size: {de.pop_size}\")\n",
        "    print(f\"  Generations: {de.n_generations}\")\n",
        "    print(f\"  Scaling Factor (F): {de.F}\")\n",
        "    print(f\"  Crossover Rate (CR): {de.CR}\")\n",
        "    print(f\"  Mutation Strategy: {de.mutation_strategy}\")\n",
        "    print(f\"  Classifier: {de.classifier}\")\n",
        "    print(f\"  Metric: {de.metric}\")\n",
        "    print(f\"  CV Folds: {de.cv_folds}\")\n",
        "    print(f\"  Threshold: {de.threshold}\")\n",
        "    \n",
        "    print(f\"\\n Final Results:\")\n",
        "    final_fitness = de.history['best_fitness'][-1]\n",
        "    final_performance = de.history['best_performance'][-1]\n",
        "    n_selected = np.sum(best_chromosome)\n",
        "    \n",
        "    print(f\"  Best Fitness: {final_fitness:.6f}\")\n",
        "    print(f\"  Best Performance: {final_performance:.6f}\")\n",
        "    print(f\"  Selected Features: {n_selected}/{de.n_features} ({n_selected/de.n_features*100:.1f}%)\")\n",
        "    \n",
        "    print(f\"\\n Evolution Statistics:\")\n",
        "    print(f\"  Initial Fitness: {de.history['best_fitness'][0]:.6f}\")\n",
        "    print(f\"  Final Fitness: {final_fitness:.6f}\")\n",
        "    print(f\"  Fitness Improvement: {final_fitness - de.history['best_fitness'][0]:.6f} \"\n",
        "          f\"({(final_fitness/de.history['best_fitness'][0]-1)*100:+.2f}%)\")\n",
        "    print(f\"  Initial Features: {de.history['best_n_features'][0]}\")\n",
        "    print(f\"  Final Features: {n_selected}\")\n",
        "    print(f\"  Feature Reduction: {de.history['best_n_features'][0] - n_selected} \"\n",
        "          f\"({(1 - n_selected/de.history['best_n_features'][0])*100:+.1f}%)\")\n",
        "    \n",
        "    print(f\"\\n Population Diversity:\")\n",
        "    print(f\"  Initial Diversity: {de.history['diversity'][0]:.2f}\")\n",
        "    print(f\"  Final Diversity: {de.history['diversity'][-1]:.2f}\")\n",
        "    print(f\"  Diversity Change: {de.history['diversity'][-1] - de.history['diversity'][0]:.2f}\")\n",
        "    \n",
        "    print(f\"\\n Selected Features:\")\n",
        "    selected_indices = np.where(best_chromosome == 1)[0]\n",
        "    for i, idx in enumerate(selected_indices):\n",
        "        print(f\"  {i+1:2d}. [{idx:2d}] {feature_names[idx]}\")\n",
        "    \n",
        "    print(f\"\\n{'='*70}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collect_results(all_results, classifiers):\n",
        "    \"\"\"\n",
        "    Collect results into a DataFrame\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "\n",
        "    for ds_name, clf_dict in all_results.items():\n",
        "        for clf_name, spiral_dict in clf_dict.items():\n",
        "            if clf_name not in classifiers:\n",
        "                continue\n",
        "\n",
        "            for spiral_type, result in spiral_dict.items():\n",
        "                rows.append({\n",
        "                    \"dataset\": ds_name,\n",
        "                    \"classifier\": clf_name,\n",
        "                    \"spiral\": spiral_type,\n",
        "                    \"perf_sel\": result[\"performance_selected\"],\n",
        "                    \"perf_all\": result[\"performance_all\"],\n",
        "                    \"n_total\": result[\"n_features\"],\n",
        "                    \"n_sel\": result[\"n_selected\"],\n",
        "                    \"ratio\": result[\"reduction_ratio\"],\n",
        "                    \"fit\": result[\"best_fitness\"],\n",
        "                    \"de_time\": result[\"de_time\"],\n",
        "                    \"eval_time\": result[\"eval_time\"],\n",
        "                    \"total_time\": result[\"total_time\"]\n",
        "                })\n",
        "\n",
        "    return pd.DataFrame(rows)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CLASSIFIER_FULL = {\n",
        "    \"rf\": \"Random Forest\",\n",
        "    \"svm\": \"Support Vector Machine\",\n",
        "    \"knn\": \"K-Nearest Neighbors\"\n",
        "}\n",
        "\n",
        "def create_summary_table(all_results):\n",
        "    \"\"\"\n",
        "    Create a comprehensive summary table of all results across datasets and classifiers\n",
        "    \"\"\"\n",
        "    if len(all_results) == 0:\n",
        "        print(\"No results to display!\")\n",
        "        return\n",
        "    \n",
        "    data = []\n",
        "\n",
        "    for ds_name, clf_dict in all_results.items():\n",
        "        for clf_name, spirals in clf_dict.items():\n",
        "            clf_pretty = CLASSIFIER_FULL.get(clf_name, clf_name)\n",
        "\n",
        "            for spiral_type, result in spirals.items():\n",
        "                data.append({\n",
        "                    'Dataset': ds_name,\n",
        "                    'Classifier': clf_pretty,\n",
        "                    'Spiral': spiral_type,\n",
        "                    'Total Features': result['n_features'],\n",
        "                    'Selected Features': result['n_selected'],\n",
        "                    'Reduction Ratio': result['reduction_ratio'],\n",
        "                    'Performance All': result['performance_all'],\n",
        "                    'Performance Selected': result['performance_selected'],\n",
        "                    'Performance Diff': result['performance_selected'] - result['performance_all'],\n",
        "                    'Best Fitness': result['best_fitness'],\n",
        "                    'DE Time (s)': result['de_time'],\n",
        "                    'Eval Time (s)': result['eval_time'],\n",
        "                    'Total Time (s)': result['total_time'],\n",
        "                })\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "    print(\"COMPREHENSIVE SUMMARY TABLE - ALL DATASETS\")\n",
        "    print(\"=\"*100)\n",
        "    print(df.to_string(index=False))\n",
        "    print(\"=\"*100)\n",
        "    \n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def statistical_analysis(all_results):\n",
        "    \"\"\"\n",
        "    Perform statistical analysis across all datasets and classifiers.\n",
        "    \"\"\"\n",
        "    if len(all_results) == 0:\n",
        "        print(\"No results to analyze!\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"STATISTICAL ANALYSIS ACROSS ALL DATASETS AND CLASSIFIERS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    dataset_names = []\n",
        "    classifier_names = []\n",
        "    spiral_names = []\n",
        "    performances_selected = []\n",
        "    performances_all = []\n",
        "    reduction_ratios = []\n",
        "    n_features_selected = []\n",
        "    best_fitnesses = []\n",
        "    de_times = []\n",
        "    total_times = []\n",
        "\n",
        "    for ds_name, clf_dict in all_results.items():\n",
        "        for clf_name, spiral_dict in clf_dict.items():\n",
        "            for spiral_type, result in spiral_dict.items():\n",
        "                dataset_names.append(ds_name)\n",
        "                classifier_names.append(clf_name)\n",
        "                spiral_names.append(spiral_type)\n",
        "                performances_selected.append(result['performance_selected'])\n",
        "                performances_all.append(result['performance_all'])\n",
        "                reduction_ratios.append(result['reduction_ratio'])\n",
        "                n_features_selected.append(result['n_selected'])\n",
        "                best_fitnesses.append(result['best_fitness'])\n",
        "                de_times.append(result['de_time'])\n",
        "                total_times.append(result['total_time'])\n",
        "\n",
        "    performances_selected = np.array(performances_selected)\n",
        "    performances_all = np.array(performances_all)\n",
        "    reduction_ratios = np.array(reduction_ratios)\n",
        "    n_features_selected = np.array(n_features_selected)\n",
        "    best_fitnesses = np.array(best_fitnesses)\n",
        "    de_times = np.array(de_times)\n",
        "    total_times = np.array(total_times)\n",
        "\n",
        "    # --- BASIC METRICS ---\n",
        "    print(\"\\nPerformance Statistics:\")\n",
        "    print(f\"  Mean (All Features):       {performances_all.mean():.4f} ± {performances_all.std():.4f}\")\n",
        "    print(f\"  Mean (Selected Features):  {performances_selected.mean():.4f} ± {performances_selected.std():.4f}\")\n",
        "    diff = performances_selected - performances_all\n",
        "    print(f\"  Mean Improvement:          {diff.mean():+.4f}\")\n",
        "\n",
        "    print(\"\\nFeature Reduction Statistics:\")\n",
        "    print(f\"  Mean Reduction Ratio:      {reduction_ratios.mean():.4f} ± {reduction_ratios.std():.4f}\")\n",
        "    print(f\"  Mean Selected Features:    {n_features_selected.mean():.2f} ± {n_features_selected.std():.2f}\")\n",
        "    print(f\"  Min Selected Features:     {n_features_selected.min()}\")\n",
        "    print(f\"  Max Selected Features:     {n_features_selected.max()}\")\n",
        "\n",
        "    best_idx = np.argmax(best_fitnesses)\n",
        "    worst_idx = np.argmin(best_fitnesses)\n",
        "\n",
        "    print(\"\\nFitness Statistics:\")\n",
        "    print(f\"  Mean Best Fitness:         {best_fitnesses.mean():.4f} ± {best_fitnesses.std():.4f}\")\n",
        "    print(f\"  Best Overall Fitness:      {best_fitnesses[best_idx]:.4f} \"\n",
        "          f\"(Dataset: {dataset_names[best_idx]}, Classifier: {classifier_names[best_idx]})\")\n",
        "    print(f\"  Worst Overall Fitness:     {best_fitnesses[worst_idx]:.4f} \"\n",
        "          f\"(Dataset: {dataset_names[worst_idx]}, Classifier: {classifier_names[worst_idx]})\")\n",
        "\n",
        "    improved = np.sum(diff > 0)\n",
        "    degraded = np.sum(diff < 0)\n",
        "    unchanged = np.sum(diff == 0)\n",
        "    total_cases = len(diff)\n",
        "\n",
        "    print(\"\\nPerformance Change Analysis:\")\n",
        "    print(f\"  Improved:  {improved}/{total_cases} ({improved/total_cases*100:.1f}%)\")\n",
        "    print(f\"  Degraded:  {degraded}/{total_cases} ({degraded/total_cases*100:.1f}%)\")\n",
        "    print(f\"  Unchanged: {unchanged}/{total_cases} ({unchanged/total_cases*100:.1f}%)\")\n",
        "\n",
        "    print(\"\\nCorrelation Analysis:\")\n",
        "    print(f\"  Reduction Ratio vs Perf:   {np.corrcoef(reduction_ratios, performances_selected)[0,1]:.4f}\")\n",
        "    print(f\"  Selected Features vs Perf: {np.corrcoef(n_features_selected, performances_selected)[0,1]:.4f}\")\n",
        "    print(f\"  Best Fitness vs Perf:      {np.corrcoef(best_fitnesses, performances_selected)[0,1]:.4f}\")\n",
        "    print(f\"  Total Time vs # Features:  {np.corrcoef(total_times, n_features_selected)[0,1]:.4f}\")\n",
        "\n",
        "    print(\"\\nAnalysis by Classifier:\")\n",
        "    unique_clfs = sorted(set(classifier_names))\n",
        "    for clf in unique_clfs:\n",
        "        idxs = [i for i,c in enumerate(classifier_names) if c == clf]\n",
        "        clf_perf = performances_selected[idxs]\n",
        "        clf_time = total_times[idxs]\n",
        "        print(f\"  {clf.upper()}:\")\n",
        "        print(f\"    Mean Performance:        {clf_perf.mean():.4f} ± {clf_perf.std():.4f}\")\n",
        "        print(f\"    Mean Total Time:         {clf_time.mean():.2f}s ± {clf_time.std():.2f}s\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
